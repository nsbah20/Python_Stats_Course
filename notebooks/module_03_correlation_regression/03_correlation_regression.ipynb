{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f25ce6",
   "metadata": {},
   "source": [
    "# Module 3: Correlation and Simple Linear Regression\n",
    "This module explores how variables relate to each other through correlation analysis and how we can model and predict these relationships using simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b739618",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "- Understand correlation coefficients and how to interpret them\n",
    "- Use scatterplots and heatmaps to explore relationships\n",
    "- Perform and interpret a simple linear regression in Python\n",
    "- Diagnose model performance and residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5bdb3",
   "metadata": {},
   "source": [
    "## üîó What is Correlation?\n",
    "Correlation measures the strength and direction of a linear relationship between two numerical variables.\n",
    "\n",
    "- **Positive correlation**: As one variable increases, so does the other\n",
    "- **Negative correlation**: As one increases, the other decreases\n",
    "- **No correlation**: No consistent pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980b32b",
   "metadata": {},
   "source": [
    "### üìè Pearson Correlation Coefficient (r)\n",
    "- Ranges from -1 to 1\n",
    "- Values close to 0 indicate weak linear relationship\n",
    "- Use Pearson for linear and Spearman for monotonic relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated dataset\n",
    "np.random.seed(42)\n",
    "x = np.random.normal(50, 10, 100)\n",
    "y = 2 * x + np.random.normal(0, 10, 100)\n",
    "df = pd.DataFrame({'Study Hours': x, 'Test Score': y})\n",
    "\n",
    "# Correlation matrix\n",
    "correlation = df.corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531f4f2",
   "metadata": {},
   "source": [
    "## üìä Visualizing Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b2248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x='Study Hours', y='Test Score')\n",
    "plt.title('Scatterplot of Study Hours vs Test Score')\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ee7e5",
   "metadata": {},
   "source": [
    "## üìê Simple Linear Regression\n",
    "Simple linear regression models the relationship between one independent variable (X) and a dependent variable (Y) using a straight line.\n",
    "\n",
    "Model: $Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ$\n",
    "- $Œ≤‚ÇÄ$: Intercept\n",
    "- $Œ≤‚ÇÅ$: Slope\n",
    "- $Œµ$: Error term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(df['Study Hours'], df['Test Score'])\n",
    "\n",
    "print(f\"Slope: {slope:.2f}\")\n",
    "print(f\"Intercept: {intercept:.2f}\")\n",
    "print(f\"R-squared: {r_value**2:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98607381",
   "metadata": {},
   "source": [
    "### üìà Plotting the Regression Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values\n",
    "predicted = intercept + slope * df['Study Hours']\n",
    "\n",
    "# Plot\n",
    "plt.scatter(df['Study Hours'], df['Test Score'], label='Observed')\n",
    "plt.plot(df['Study Hours'], predicted, color='red', label='Fitted Line')\n",
    "plt.xlabel('Study Hours')\n",
    "plt.ylabel('Test Score')\n",
    "plt.legend()\n",
    "plt.title('Linear Regression Fit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f1bb8",
   "metadata": {},
   "source": [
    "## üß™ Residual Analysis\n",
    "Residuals are the differences between observed and predicted values.\n",
    "A residual plot helps verify linearity and homoscedasticity assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = df['Test Score'] - predicted\n",
    "plt.scatter(predicted, residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Predicted Score')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d76575",
   "metadata": {},
   "source": [
    "## ‚úÖ Practice Exercises\n",
    "1. Simulate two variables with a negative correlation and calculate Pearson‚Äôs r.\n",
    "2. Plot a regression line for any two continuous variables and interpret the slope.\n",
    "3. Use a real dataset (e.g., seaborn's `tips` or `penguins`) to run a regression.\n",
    "4. Create a residual plot. What patterns do you see?\n",
    "5. Reflect: What does an R¬≤ of 0.80 tell you about the model?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
